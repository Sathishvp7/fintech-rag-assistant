{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "137c57a6",
      "metadata": {
        "id": "137c57a6"
      },
      "source": [
        "## RAG DEVELOPMENT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6o1Ff3WqNNj",
        "outputId": "c6c7b9cb-b693-48cd-8517-f00f1d8eacd2"
      },
      "id": "x6o1Ff3WqNNj",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd MyDrive/RAG_projects/DS-RPC-01/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps8kX-JMqNQB",
        "outputId": "f132e164-1f6f-4e08-bf07-d8a86fff3ea7"
      },
      "id": "ps8kX-JMqNQB",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/RAG_projects/DS-RPC-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install OpenAI, and LangChain dependencies"
      ],
      "metadata": {
        "id": "2fw53idlrIc9"
      },
      "id": "2fw53idlrIc9"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.3.10\n",
        "!pip install langchain-openai==0.2.12\n",
        "!pip install langchain-community==0.3.11\n",
        "!pip install dill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lDqsFt0tqNSa",
        "outputId": "39c83bf2-a213-42c1-b097-0392796ce9b0"
      },
      "id": "lDqsFt0tqNSa",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.3.10\n",
            "  Downloading langchain-0.3.10-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.10) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.10) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.10) (3.11.15)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.22 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.10) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.10) (0.3.8)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.10)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy<2,>=1.22.4 (from langchain==0.3.10)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.10) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.10) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.10) (9.1.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.10) (1.20.1)\n",
            "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.4.0,>=0.3.22 (from langchain==0.3.10)\n",
            "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.64-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_core-0.3.63-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain==0.3.10) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain==0.3.10) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.22->langchain==0.3.10) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.10) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.10) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.10) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.10) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.10) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.10) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.10) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.10) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.22->langchain==0.3.10) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.10) (1.3.1)\n",
            "Downloading langchain-0.3.10-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.63-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.5/438.5 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, langsmith, langchain-core, langchain\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.45\n",
            "    Uninstalling langsmith-0.3.45:\n",
            "      Successfully uninstalled langsmith-0.3.45\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.65\n",
            "    Uninstalling langchain-core-0.3.65:\n",
            "      Successfully uninstalled langchain-core-0.3.65\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.25\n",
            "    Uninstalling langchain-0.3.25:\n",
            "      Successfully uninstalled langchain-0.3.25\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-0.3.10 langchain-core-0.3.63 langsmith-0.1.147 numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "8b42e0f610eb438f843124ca4be74122"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai==0.2.12\n",
            "  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.2.12) (0.3.63)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.55.3 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.2.12) (1.86.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.2.12) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.1.147)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (4.14.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.11.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.12) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.12) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.55.3->langchain-openai==0.2.12) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<0.4.0,>=0.3.21->langchain-openai==0.2.12) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.12) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.12) (2.4.0)\n",
            "Downloading langchain_openai-0.2.12-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-openai\n",
            "Successfully installed langchain-openai-0.2.12\n",
            "Collecting langchain-community==0.3.11\n",
            "  Downloading langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (2.0.41)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (3.11.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.11)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community==0.3.11)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.11 (from langchain-community==0.3.11)\n",
            "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (0.3.63)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (0.1.147)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.11)\n",
            "  Downloading pydantic_settings-2.10.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.11) (9.1.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.11) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.24 (from langchain-community==0.3.11)\n",
            "  Using cached langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (2.11.7)\n",
            "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain<0.4.0,>=0.3.11 (from langchain-community==0.3.11)\n",
            "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.11)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.11) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.11) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.11) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.11) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.11) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.11) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain-community==0.3.11) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.11->langchain-community==0.3.11) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.11)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.11) (1.3.1)\n",
            "Downloading langchain_community-0.3.11-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain, langchain-community\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.10\n",
            "    Uninstalling langchain-0.3.10:\n",
            "      Successfully uninstalled langchain-0.3.10\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.25 langchain-community-0.3.11 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.0 python-dotenv-1.1.0 typing-inspect-0.9.0\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (0.3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# takes 2 - 5 mins to install on Colab\n",
        "!pip install \"unstructured[all-docs]==0.14.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-sZtyFXuqNU4",
        "outputId": "d56bdd34-e6c7-4fc3-8d65-833f01c877eb"
      },
      "id": "-sZtyFXuqNU4",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unstructured==0.14.0 (from unstructured[all-docs]==0.14.0)\n",
            "  Downloading unstructured-0.14.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (5.2.0)\n",
            "Collecting filetype (from unstructured==0.14.0->unstructured[all-docs]==0.14.0)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured==0.14.0->unstructured[all-docs]==0.14.0)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (5.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (3.9.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (4.13.4)\n",
            "Collecting emoji (from unstructured==0.14.0->unstructured[all-docs]==0.14.0)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.6.7)\n",
            "Collecting python-iso639 (from unstructured==0.14.0->unstructured[all-docs]==0.14.0)\n",
            "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langdetect (from unstructured==0.14.0->unstructured[all-docs]==0.14.0)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.26.4)\n",
            "Collecting rapidfuzz (from unstructured==0.14.0->unstructured[all-docs]==0.14.0)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting backoff (from unstructured==0.14.0->unstructured[all-docs]==0.14.0)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (4.14.0)\n",
            "Collecting unstructured-client (from unstructured==0.14.0->unstructured[all-docs]==0.14.0)\n",
            "  Downloading unstructured_client-0.36.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.17.2)\n",
            "Collecting pikepdf (from unstructured[all-docs]==0.14.0)\n",
            "  Downloading pikepdf-9.9.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting pdfminer.six (from unstructured[all-docs]==0.14.0)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting python-pptx<=0.6.23 (from unstructured[all-docs]==0.14.0)\n",
            "  Downloading python_pptx-0.6.23-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]==0.14.0) (3.5)\n",
            "Collecting pdf2image (from unstructured[all-docs]==0.14.0)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pypandoc (from unstructured[all-docs]==0.14.0)\n",
            "  Downloading pypandoc-1.15-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting onnx (from unstructured[all-docs]==0.14.0)\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting unstructured.pytesseract>=0.3.12 (from unstructured[all-docs]==0.14.0)\n",
            "  Downloading unstructured.pytesseract-0.3.15-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting google-cloud-vision (from unstructured[all-docs]==0.14.0)\n",
            "  Downloading google_cloud_vision-3.10.2-py3-none-any.whl.metadata (9.6 kB)\n",
            "Collecting python-docx (from unstructured[all-docs]==0.14.0)\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting pypdf (from unstructured[all-docs]==0.14.0)\n",
            "  Downloading pypdf-5.6.1-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]==0.14.0) (2.2.2)\n",
            "Collecting pillow-heif (from unstructured[all-docs]==0.14.0)\n",
            "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]==0.14.0) (3.8)\n",
            "Collecting msg-parser (from unstructured[all-docs]==0.14.0)\n",
            "  Downloading msg_parser-1.2.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting unstructured-inference==0.7.31 (from unstructured[all-docs]==0.14.0)\n",
            "  Downloading unstructured_inference-0.7.31-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]==0.14.0) (3.1.5)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.11/dist-packages (from unstructured[all-docs]==0.14.0) (2.0.2)\n",
            "Collecting layoutparser[layoutmodels,tesseract] (from unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading layoutparser-0.3.4-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (from unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.0.20)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.33.0)\n",
            "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.11/dist-packages (from unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (4.11.0.86)\n",
            "Collecting onnxruntime>=1.17.0 (from unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (4.52.4)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx<=0.6.23->unstructured[all-docs]==0.14.0) (11.2.1)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx<=0.6.23->unstructured[all-docs]==0.14.0)\n",
            "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from unstructured.pytesseract>=0.3.12->unstructured[all-docs]==0.14.0) (24.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2.7)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.9.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision->unstructured[all-docs]==0.14.0) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision->unstructured[all-docs]==0.14.0) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-vision->unstructured[all-docs]==0.14.0) (5.29.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.17.0)\n",
            "Collecting olefile>=0.46 (from msg-parser->unstructured[all-docs]==0.14.0)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (4.67.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl->unstructured[all-docs]==0.14.0) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->unstructured[all-docs]==0.14.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->unstructured[all-docs]==0.14.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->unstructured[all-docs]==0.14.0) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six->unstructured[all-docs]==0.14.0) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six->unstructured[all-docs]==0.14.0) (43.0.3)\n",
            "Collecting Deprecated (from pikepdf->unstructured[all-docs]==0.14.0)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2025.6.15)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (24.1.0)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.28.1)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.6.0)\n",
            "Requirement already satisfied: pydantic>=2.11.2 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]==0.14.0) (1.17.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.16.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.17.0->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (1.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.11.2->unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (1.1.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (1.15.3)\n",
            "Collecting iopath (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdfplumber (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.21.0+cu124)\n",
            "Collecting effdet (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting pytesseract (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]==0.14.0) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: timm>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (1.0.15)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (2.0.10)\n",
            "Requirement already satisfied: omegaconf>=2.0 in /usr/local/lib/python3.11/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (2.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (1.3.0)\n",
            "Collecting portalocker (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (4.9.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (3.0.2)\n",
            "Downloading unstructured-0.14.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_inference-0.7.31-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-0.6.23-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured.pytesseract-0.3.15-py3-none-any.whl (14 kB)\n",
            "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_cloud_vision-3.10.2-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.9/527.9 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msg_parser-1.2.0-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pikepdf-9.9.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypandoc-1.15-py3-none-any.whl (21 kB)\n",
            "Downloading pypdf-5.6.1-py3-none-any.whl (304 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.6/304.6 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.36.0-py3-none-any.whl (195 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.8/195.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: langdetect, iopath\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=a08ef059625d415783770ba84b2f407d43630a2f7182acb6d4c60efe8e8040a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=1cd9c6bb4ebd24950a5c18ce06337b58e909ad6c9c30d7388d65b04b9e1bb023\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built langdetect iopath\n",
            "Installing collected packages: filetype, XlsxWriter, unstructured.pytesseract, rapidfuzz, python-magic, python-iso639, python-docx, pytesseract, pypdfium2, pypdf, pypandoc, portalocker, pillow-heif, pdf2image, onnx, olefile, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, langdetect, humanfriendly, emoji, Deprecated, backoff, python-pptx, pikepdf, nvidia-cusparse-cu12, nvidia-cudnn-cu12, msg-parser, iopath, coloredlogs, unstructured-client, pdfminer.six, onnxruntime, nvidia-cusolver-cu12, unstructured, pdfplumber, layoutparser, google-cloud-vision, effdet, unstructured-inference\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed Deprecated-1.2.18 XlsxWriter-3.2.5 backoff-2.2.1 coloredlogs-15.0.1 effdet-0.4.1 emoji-2.14.1 filetype-1.2.0 google-cloud-vision-3.10.2 humanfriendly-10.0 iopath-0.1.10 langdetect-1.0.9 layoutparser-0.3.4 msg-parser-1.2.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 olefile-0.47 onnx-1.18.0 onnxruntime-1.22.0 pdf2image-1.17.0 pdfminer.six-20250506 pdfplumber-0.11.7 pikepdf-9.9.0 pillow-heif-0.22.0 portalocker-3.2.0 pypandoc-1.15 pypdf-5.6.1 pypdfium2-4.30.1 pytesseract-0.3.13 python-docx-1.2.0 python-iso639-2025.2.18 python-magic-0.4.27 python-pptx-0.6.23 rapidfuzz-3.13.0 unstructured-0.14.0 unstructured-client-0.36.0 unstructured-inference-0.7.31 unstructured.pytesseract-0.3.15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "a7d55808474b4910abf8815b9d62b14f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp4Z4b6YqNXE",
        "outputId": "fcfaee9b-adcc-48e2-91cf-f2cfc9d587fb"
      },
      "id": "wp4Z4b6YqNXE",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c661b895",
      "metadata": {
        "id": "c661b895"
      },
      "source": [
        "## Install Chroma Vector DB and LangChain wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8zIBoUypsmM",
        "outputId": "849a82a7-b0fc-4439-a2db-39270b5c2d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-chroma==0.1.4\n",
            "  Downloading langchain_chroma-0.1.4-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain-chroma==0.1.4)\n",
            "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: fastapi<1,>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma==0.1.4) (0.115.12)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1.40 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma==0.1.4) (0.3.63)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-chroma==0.1.4) (1.26.4)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.11.7)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.34.3)\n",
            "Collecting posthog>=2.4.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (4.14.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.22.0)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.73.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (9.1.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (13.9.4)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1,>=0.95.2->langchain-chroma==0.1.4) (0.46.2)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.126 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1.40->langchain-chroma==0.1.4) (0.1.147)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1.40->langchain-chroma==0.1.4) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1.40->langchain-chroma==0.1.4) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1.40->langchain-chroma==0.1.4) (3.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.4.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.126->langchain-core<0.4,>=0.1.40->langchain-chroma==0.1.4) (1.0.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading opentelemetry_util_http-0.55b1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.33.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.1.0)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4)\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (15.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.1.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (3.4.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma==0.1.4) (0.6.1)\n",
            "Downloading langchain_chroma-0.1.4-py3-none-any.whl (10 kB)\n",
            "Downloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl (31 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.55b1-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=0662f60e38c801c7635ff4ece628368e663534b19ca886b25d9cbeffdc6a9ad6\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, overrides, opentelemetry-util-http, opentelemetry-proto, mmh3, httptools, chroma-hnswlib, bcrypt, asgiref, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, tokenizers, opentelemetry-semantic-conventions, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb, langchain-chroma\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.52.4 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 bcrypt-4.3.0 chroma-hnswlib-0.7.6 chromadb-0.5.23 durationpy-0.10 httptools-0.6.4 kubernetes-33.1.0 langchain-chroma-0.1.4 mmh3-5.1.0 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-instrumentation-0.55b1 opentelemetry-instrumentation-asgi-0.55b1 opentelemetry-instrumentation-fastapi-0.55b1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 opentelemetry-util-http-0.55b1 overrides-7.7.0 posthog-5.4.0 pypika-0.48.9 tokenizers-0.20.3 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-chroma==0.1.4"
      ],
      "id": "w8zIBoUypsmM"
    },
    {
      "cell_type": "markdown",
      "id": "bc544add",
      "metadata": {
        "id": "bc544add"
      },
      "source": [
        "## Enter Open AI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d6e219f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6e219f2",
        "outputId": "886b4b29-77cf-4fa8-8cbb-9d0d6381234d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Open AI API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# Enter Open AI API Key\n",
        "from getpass import getpass\n",
        "\n",
        "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "293b13f9",
      "metadata": {
        "id": "293b13f9"
      },
      "outputs": [],
      "source": [
        "# Setup Environment Variables\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "897d69f6",
      "metadata": {
        "id": "897d69f6"
      },
      "source": [
        "### Open AI Embedding Models\n",
        "\n",
        "LangChain enables us to access Open AI embedding models which include the newest models: a smaller and highly efficient `text-embedding-3-small` model, and a larger and more powerful `text-embedding-3-large` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b4a84ae9",
      "metadata": {
        "id": "b4a84ae9"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n",
        "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68bfe288",
      "metadata": {
        "id": "68bfe288"
      },
      "source": [
        "## Loading and Processing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1020a3a",
      "metadata": {
        "id": "a1020a3a"
      },
      "source": [
        "### Get the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "e78ecfe1",
      "metadata": {
        "id": "e78ecfe1"
      },
      "outputs": [],
      "source": [
        "# All the processed data will be stored in processed_docs\n",
        "# which going to ingest in to chroma DB\n",
        "processed_docs = []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63e8bf05",
      "metadata": {
        "id": "63e8bf05"
      },
      "source": [
        "#### HR DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "7a751725",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "7a751725",
        "outputId": "a0de5d55-f4ff-486b-a43b-128681cc4a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of dataset (100, 15)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  employee_id       full_name            role department  \\\n",
              "0  FINEMP1000    Aadhya Patel   Sales Manager      Sales   \n",
              "1  FINEMP1001  Isha Chowdhury  Credit Officer    Finance   \n",
              "\n",
              "                          email   location date_of_birth date_of_joining  \\\n",
              "0    aadhya.patel@fintechco.com  Ahmedabad    1991-04-03      2018-11-20   \n",
              "1  isha.chowdhury@fintechco.com       Pune    1995-09-21      2021-05-20   \n",
              "\n",
              "   manager_id      salary  leave_balance  leaves_taken  attendance_pct  \\\n",
              "0  FINEMP1006  1332478.37             22            11           99.31   \n",
              "1  FINEMP1005  1491158.23              8             3           85.15   \n",
              "\n",
              "   performance_rating last_review_date  \n",
              "0                   3       2024-05-21  \n",
              "1                   5       2024-01-20  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31f1b1e3-45bc-47ef-8ad3-ac61710a0f58\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>employee_id</th>\n",
              "      <th>full_name</th>\n",
              "      <th>role</th>\n",
              "      <th>department</th>\n",
              "      <th>email</th>\n",
              "      <th>location</th>\n",
              "      <th>date_of_birth</th>\n",
              "      <th>date_of_joining</th>\n",
              "      <th>manager_id</th>\n",
              "      <th>salary</th>\n",
              "      <th>leave_balance</th>\n",
              "      <th>leaves_taken</th>\n",
              "      <th>attendance_pct</th>\n",
              "      <th>performance_rating</th>\n",
              "      <th>last_review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FINEMP1000</td>\n",
              "      <td>Aadhya Patel</td>\n",
              "      <td>Sales Manager</td>\n",
              "      <td>Sales</td>\n",
              "      <td>aadhya.patel@fintechco.com</td>\n",
              "      <td>Ahmedabad</td>\n",
              "      <td>1991-04-03</td>\n",
              "      <td>2018-11-20</td>\n",
              "      <td>FINEMP1006</td>\n",
              "      <td>1332478.37</td>\n",
              "      <td>22</td>\n",
              "      <td>11</td>\n",
              "      <td>99.31</td>\n",
              "      <td>3</td>\n",
              "      <td>2024-05-21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FINEMP1001</td>\n",
              "      <td>Isha Chowdhury</td>\n",
              "      <td>Credit Officer</td>\n",
              "      <td>Finance</td>\n",
              "      <td>isha.chowdhury@fintechco.com</td>\n",
              "      <td>Pune</td>\n",
              "      <td>1995-09-21</td>\n",
              "      <td>2021-05-20</td>\n",
              "      <td>FINEMP1005</td>\n",
              "      <td>1491158.23</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>85.15</td>\n",
              "      <td>5</td>\n",
              "      <td>2024-01-20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31f1b1e3-45bc-47ef-8ad3-ac61710a0f58')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-31f1b1e3-45bc-47ef-8ad3-ac61710a0f58 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-31f1b1e3-45bc-47ef-8ad3-ac61710a0f58');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-24716c98-e008-4998-b7f9-ca0af7111cf9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24716c98-e008-4998-b7f9-ca0af7111cf9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-24716c98-e008-4998-b7f9-ca0af7111cf9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"employee_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"FINEMP1083\",\n          \"FINEMP1053\",\n          \"FINEMP1070\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 83,\n        \"samples\": [\n          \"Saanvi Bhat\",\n          \"Aadhya Patel\",\n          \"Krishna Gupta\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"role\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Sales Manager\",\n          \"Software Engineer\",\n          \"Data Scientist\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"department\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"Product\",\n          \"Data\",\n          \"Sales\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"email\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 83,\n        \"samples\": [\n          \"saanvi.bhat@fintechco.com\",\n          \"aadhya.patel@fintechco.com\",\n          \"krishna.gupta@fintechco.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Chennai\",\n          \"Pune\",\n          \"Mumbai\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date_of_birth\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"1982-07-13\",\n          \"1985-02-08\",\n          \"1983-07-25\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date_of_joining\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"2019-08-23\",\n          \"2021-04-23\",\n          \"2022-03-25\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"manager_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"FINEMP1002\",\n          \"FINEMP1005\",\n          \"FINEMP1004\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"salary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 491800.94239773566,\n        \"min\": 305337.03,\n        \"max\": 1982774.95,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          1413177.7,\n          1502270.01,\n          1872784.84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"leave_balance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 0,\n        \"max\": 29,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          27,\n          9,\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"leaves_taken\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 26,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          11,\n          26,\n          14\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attendance_pct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.949875587358992,\n        \"min\": 80.02,\n        \"max\": 99.98,\n        \"num_unique_values\": 99,\n        \"samples\": [\n          85.81,\n          94.28,\n          97.67\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"performance_rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"last_review_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 93,\n        \"samples\": [\n          \"2025-04-28\",\n          \"2025-03-31\",\n          \"2025-01-31\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "import pandas as pd\n",
        "# loading hr data\n",
        "df = pd.read_csv('data/hr/hr_data.csv')\n",
        "print('Shape of dataset',df.shape)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "69839211",
      "metadata": {
        "id": "69839211"
      },
      "outputs": [],
      "source": [
        "from langchain.docstore.document import Document\n",
        "\n",
        "# Document loaders to load data from a source as a Document data type object\n",
        "# Document has a piece of text content and associated metadata\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    content = (\n",
        "        f\"Employee {row['full_name']} (ID: {row['employee_id']}) works as a {row['role']} in the {row['department']} department. \"\n",
        "        f\"Their email is {row['email']} and they are based in {row['location']}. \"\n",
        "        f\"Born on {row['date_of_birth']}, they joined the company on {row['date_of_joining']} and report to manager ID {row['manager_id']}. \"\n",
        "        f\"Their current salary is {row['salary']}, with {row['leave_balance']} leave days remaining out of {row['leaves_taken']} taken. \"\n",
        "        f\"Attendance percentage is {row['attendance_pct']}% and their latest performance rating is {row['performance_rating']} \"\n",
        "        f\"(last reviewed on {row['last_review_date']}).\"\n",
        "    )\n",
        "    metadata = row.to_dict()\n",
        "    metadata[\"file_name\"] = \"hr_data.csv\"\n",
        "    metadata[\"page_no\"] = index + 1\n",
        "    metadata[\"access_level\"] = \"hr\"\n",
        "\n",
        "    # metadata is optional but recommended - core usage is during retrivel based on filter/condition, without metadata difficult process based on conditions\n",
        "    processed_docs.append(Document(page_content=content, metadata=metadata))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "4418c94f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4418c94f",
        "outputId": "7f38a48f-d295-46e5-d7b5-8389b6b635d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Processed data count 100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'employee_id': 'FINEMP1000', 'full_name': 'Aadhya Patel', 'role': 'Sales Manager', 'department': 'Sales', 'email': 'aadhya.patel@fintechco.com', 'location': 'Ahmedabad', 'date_of_birth': '1991-04-03', 'date_of_joining': '2018-11-20', 'manager_id': 'FINEMP1006', 'salary': 1332478.37, 'leave_balance': 22, 'leaves_taken': 11, 'attendance_pct': 99.31, 'performance_rating': 3, 'last_review_date': '2024-05-21', 'file_name': 'hr_data.csv', 'page_no': 1, 'access_level': 'hr'}, page_content='Employee Aadhya Patel (ID: FINEMP1000) works as a Sales Manager in the Sales department. Their email is aadhya.patel@fintechco.com and they are based in Ahmedabad. Born on 1991-04-03, they joined the company on 2018-11-20 and report to manager ID FINEMP1006. Their current salary is 1332478.37, with 22 leave days remaining out of 11 taken. Attendance percentage is 99.31% and their latest performance rating is 3 (last reviewed on 2024-05-21).')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "print('Total Processed data count', len(processed_docs))\n",
        "# sample data to view\n",
        "processed_docs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea1427b8",
      "metadata": {
        "id": "ea1427b8"
      },
      "source": [
        "#### FINANCE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "31546413",
      "metadata": {
        "id": "31546413"
      },
      "outputs": [],
      "source": [
        "# The Finance dataset is in .md(markdown) format\n",
        "# LangChain implements an UnstructuredMarkdownLoader object which uses the Unstructured library to load data from Markdown files\n",
        "# Langchain uses the Unstructured.io(famous doc loader opensource) library under the hood.\n",
        "\n",
        "from langchain_community.document_loaders import UnstructuredMarkdownLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "9dffebf4",
      "metadata": {
        "id": "9dffebf4"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "def count_tokens_in_file(file_path: str, model: str = \"gpt-4\") -> int:\n",
        "    # Load tokenizer\n",
        "    encoding = tiktoken.encoding_for_model(model)\n",
        "\n",
        "    # Read content\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        content = f.read()\n",
        "\n",
        "    # Tokenize and count\n",
        "    tokens = encoding.encode(content)\n",
        "    print(f\"Total tokens in '{file_path}': {len(tokens)}\")\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "a3d1f58f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3d1f58f",
        "outputId": "bb5f4266-0512-49c0-fcea-0163e06be717"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens in 'data/finance/financial_summary.md': 1420\n"
          ]
        }
      ],
      "source": [
        "count_tokens_in_file('data/finance/financial_summary.md')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c714179f",
      "metadata": {
        "id": "c714179f"
      },
      "source": [
        "GPT-4o Mini supports a context window of up to 128,000 tokens, allowing for substantial input sizes. Additionally, it can generate up to 16,384 tokens in a single response. ([techtarget.com][1])\n",
        "\n",
        "However, if you're using GPT-4o Mini through Azure OpenAI, be aware that some users have reported practical input token limits around 35,000 tokens, despite the documented 128,000-token context window. This discrepancy may be due to specific deployment configurations or subscription tiers. ([learn.microsoft.com][2])\n",
        "\n",
        "In your case, with a 1420-token document, you're well within both the official and observed limits. Therefore, we're proceed to load the document without splitting(mode = single).\n",
        "\n",
        "[1]: https://www.techtarget.com/whatis/feature/GPT-4o-explained-Everything-you-need-to-know?utm_source=chatgpt.com \"GPT-4o explained: Everything you need to know - TechTarget\"\n",
        "[2]: https://learn.microsoft.com/en-us/answers/questions/2121835/gpt-4o-has-a-35k-input-token-limit?utm_source=chatgpt.com \"GPT-4o has a 35k input token limit - Microsoft Q&A\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "d94e3f23",
      "metadata": {
        "id": "d94e3f23"
      },
      "outputs": [],
      "source": [
        "loader_summary = UnstructuredMarkdownLoader(\"data/finance/financial_summary.md\", mode=\"single\")\n",
        "docs_summary  = loader_summary.load()\n",
        "\n",
        "docs_summary[0].metadata[\"access_level\"] = \"finance\"\n",
        "docs_summary[0].metadata[\"file_name\"] = \"financial_summary.md\"\n",
        "docs_summary[0].metadata[\"page_no\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "7f9808cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f9808cb",
        "outputId": "c819a8a6-3453-4cfb-89c1-4ef24dece67c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After adding finance summary 101\n"
          ]
        }
      ],
      "source": [
        "processed_docs.append(docs_summary[0])\n",
        "print('After adding finance summary', len(processed_docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "9dd90158",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dd90158",
        "outputId": "1a8071c9-3e04-4bdd-ed44-9eac816ae75d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens in 'data/finance/quarterly_financial_report.md': 2281\n"
          ]
        }
      ],
      "source": [
        "# Read the file content\n",
        "count_tokens_in_file('data/finance/quarterly_financial_report.md')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "c3e09af6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3e09af6",
        "outputId": "f4b53fa4-a7ef-4166-de36-a806a8857114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After adding finance report 102\n"
          ]
        }
      ],
      "source": [
        "loader_report = UnstructuredMarkdownLoader(\"data/finance/quarterly_financial_report.md\", mode=\"single\")\n",
        "docs_report  = loader_report.load()\n",
        "docs_report[0].metadata[\"access_level\"] = \"finance\"\n",
        "docs_report[0].metadata[\"file_name\"] = \"quarterly_financial_report.md\"\n",
        "docs_report[0].metadata[\"page_no\"] = 1\n",
        "processed_docs.append(docs_report[0])\n",
        "print('After adding finance report', len(processed_docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "811683bf",
      "metadata": {
        "id": "811683bf"
      },
      "source": [
        "#### MARKETING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader_q1 = UnstructuredMarkdownLoader(\"data/marketing/marketing_report_q1_2024.md\", mode=\"single\")\n",
        "docs_q1  = loader_q1.load()\n",
        "docs_q1[0].metadata[\"access_level\"] = \"marketing\"\n",
        "docs_q1[0].metadata[\"file_name\"] = \"marketing_report_q1_2024.md\"\n",
        "docs_q1[0].metadata[\"page_no\"] = 1\n",
        "processed_docs.append(docs_q1[0])\n",
        "\n",
        "loader_q2 = UnstructuredMarkdownLoader(\"data/marketing/marketing_report_q2_2024.md\", mode=\"single\")\n",
        "docs_q2  = loader_q2.load()\n",
        "docs_q2[0].metadata[\"access_level\"] = \"marketing\"\n",
        "docs_q2[0].metadata[\"file_name\"] = \"marketing_report_q2_2024.md\"\n",
        "docs_q2[0].metadata[\"page_no\"] = 1\n",
        "processed_docs.append(docs_q2[0])\n",
        "\n",
        "loader_q3 = UnstructuredMarkdownLoader(\"data/marketing/marketing_report_q3_2024.md\", mode=\"single\")\n",
        "docs_q3  = loader_q3.load()\n",
        "docs_q3[0].metadata[\"access_level\"] = \"marketing\"\n",
        "docs_q3[0].metadata[\"file_name\"] = \"marketing_report_q3_2024.md\"\n",
        "docs_q3[0].metadata[\"page_no\"] = 1\n",
        "processed_docs.append(docs_q3[0])\n",
        "\n",
        "loader_q4 = UnstructuredMarkdownLoader(\"data/marketing/market_report_q4_2024.md\", mode=\"single\")\n",
        "docs_q4  = loader_q4.load()\n",
        "docs_q4[0].metadata[\"access_level\"] = \"marketing\"\n",
        "docs_q4[0].metadata[\"file_name\"] = \"market_report_q4_2024.md\"\n",
        "docs_q4[0].metadata[\"page_no\"] = 1\n",
        "processed_docs.append(docs_q4[0])\n",
        "\n",
        "loader_q_all = UnstructuredMarkdownLoader(\"data/marketing/marketing_report_2024.md\", mode=\"single\")\n",
        "docs_q_all  = loader_q_all.load()\n",
        "docs_q_all[0].metadata[\"access_level\"] = \"marketing\"\n",
        "docs_q_all[0].metadata[\"file_name\"] = \"marketing_report_2024.md\"\n",
        "docs_q_all[0].metadata[\"page_no\"] = 1\n",
        "processed_docs.append(docs_q_all[0])\n",
        "\n",
        "print('After adding marketing dataset', len(processed_docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7XiS5PCsxyk",
        "outputId": "5ee039d6-25a3-4628-9a78-b3d4567a1ec8"
      },
      "id": "O7XiS5PCsxyk",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After adding marketing dataset 107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_q1[0].metadata['source']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DcFTvGBAs49e",
        "outputId": "35b1615a-af82-44ed-9ed8-93a241fe8fb9"
      },
      "id": "DcFTvGBAs49e",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data/marketing/marketing_report_q1_2024.md'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "cf73c91e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf73c91e",
        "outputId": "9a623a95-3b7f-4d41-c0e0-5c1087882dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens in 'data/marketing/marketing_report_q1_2024.md': 1269\n",
            "Total tokens in 'data/marketing/marketing_report_q2_2024.md': 1311\n",
            "Total tokens in 'data/marketing/marketing_report_q3_2024.md': 1252\n",
            "Total tokens in 'data/marketing/market_report_q4_2024.md': 1351\n",
            "Total tokens in 'data/marketing/marketing_report_2024.md': 1393\n"
          ]
        }
      ],
      "source": [
        "# Count tokens in page_content\n",
        "my_list = [docs_q1,docs_q2,docs_q3,docs_q4,docs_q_all]\n",
        "for i, doc in enumerate(my_list):\n",
        "    count_tokens_in_file(doc[0].metadata['source'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccbfb25b",
      "metadata": {
        "id": "ccbfb25b"
      },
      "source": [
        "#### Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "0d7efeb0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d7efeb0",
        "outputId": "9a25c2c9-7465-4b17-ed7c-2e039d6d3b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens in 'data/engineering/engineering_master_doc.md': 6658\n"
          ]
        }
      ],
      "source": [
        "count_tokens_in_file('data/engineering/engineering_master_doc.md')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "b4ec56d2",
      "metadata": {
        "id": "b4ec56d2"
      },
      "outputs": [],
      "source": [
        "from langchain.docstore.document import Document\n",
        "import os\n",
        "\n",
        "def parse_markdown_with_headings(file_path, access_level=\"engineer\"):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    docs = []\n",
        "    current_heading = \"\"\n",
        "    current_level = \"\"\n",
        "    buffer = []\n",
        "    page_cnt = 1\n",
        "    file_name = os.path.basename(file_path)\n",
        "\n",
        "    def flush_buffer(page_cnt, heading, level):\n",
        "        if heading and buffer:\n",
        "            content = heading + \"\\n\" + \"\\n\".join(buffer).strip()\n",
        "            docs.append(Document(\n",
        "                page_content=content,\n",
        "                metadata={\n",
        "                    \"file_name\": file_name,\n",
        "                    \"page_no\": page_cnt,\n",
        "                    \"access_level\": access_level,\n",
        "                    \"heading_level\": level\n",
        "                }\n",
        "            ))\n",
        "            return page_cnt + 1\n",
        "        return page_cnt\n",
        "\n",
        "    for line in lines:\n",
        "        stripped = line.strip()\n",
        "\n",
        "        if stripped.startswith(\"# \"):  # Main title (H1)\n",
        "            page_cnt = flush_buffer(page_cnt, current_heading, current_level)\n",
        "            current_heading = stripped\n",
        "            current_level = \"H1\"\n",
        "            buffer = []\n",
        "        elif stripped.startswith(\"## \"):  # Heading (H2)\n",
        "            page_cnt = flush_buffer(page_cnt, current_heading, current_level)\n",
        "            current_heading = stripped\n",
        "            current_level = \"H2\"\n",
        "            buffer = []\n",
        "        elif stripped.startswith(\"### \"):  # Subheading (H3)\n",
        "            page_cnt = flush_buffer(page_cnt, current_heading, current_level)\n",
        "            current_heading = stripped\n",
        "            current_level = \"H3\"\n",
        "            buffer = []\n",
        "        else:\n",
        "            if stripped:\n",
        "                buffer.append(stripped)\n",
        "\n",
        "    # Final flush\n",
        "    page_cnt = flush_buffer(page_cnt, current_heading, current_level)\n",
        "\n",
        "    return docs\n",
        "\n",
        "docs_engineering = parse_markdown_with_headings(file_path = \"data/engineering/engineering_master_doc.md\",access_level=\"engineer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "952295f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "952295f7",
        "outputId": "29cf0cbf-7b44-42dd-93f4-e629e14d4bf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "Content: ### 6.3 Defect Management\n",
            "#### 6.3.1 Bug Tracking\n",
            "* Jira for logging and tracking defects\n",
            "* Required fields: steps to reproduce, expected vs. actual results, environment\n",
            "* Severity classification:\n",
            "* S1 (Critical): System unusable, data corruption, security vulnerability\n",
            "* S2 (Major): Major function impacted, no workaround\n",
            "* S3 (Minor): Minor impact, workaround available\n",
            "* S4 (Cosmetic): UI issues, typos, non-functional issues\n",
            "#### 6.3.2 Defect SLAs\n",
            "* S1: Resolution within 24 hours, immediate patch release if needed\n",
            "* S2: Resolution within 72 hours, included in next scheduled release\n",
            "* S3: Resolution within 2 weeks\n",
            "* S4: Prioritized based on business impact\n",
            "#### 6.3.3 Bug Triage Process\n",
            "* Daily triage meeting for new bugs\n",
            "* Weekly bug review for outstanding issues\n",
            "* Monthly quality metrics review\n",
            "Metadata: {'file_name': 'engineering_master_doc.md', 'page_no': 21, 'access_level': 'engineer', 'heading_level': 'H3'}\n",
            "---\n",
            "Content: ### 7.1 CI/CD Pipeline\n",
            "#### 7.1.1 Continuous Integration\n",
            "* Every commit triggers:\n",
            "* Code compilation and static analysis\n",
            "* Unit and integration tests\n",
            "* Security scanning\n",
            "* Code quality checks\n",
            "* Feature branches built and deployed to ephemeral environments\n",
            "#### 7.1.2 Continuous Deployment\n",
            "* **Staging Environment**:\n",
            "* Automatic deployment from the `develop` branch\n",
            "* Full test suite execution\n",
            "* Performance testing\n",
            "* **Production Environment**:\n",
            "* Scheduled deployments (bi-weekly)\n",
            "* Blue-green deployment strategy\n",
            "* Automated smoke tests post-deployment\n",
            "* Automated rollback on failure\n",
            "#### 7.1.3 Pipeline Technologies\n",
            "* Jenkins for build orchestration\n",
            "* ArgoCD for GitOps-based deployment\n",
            "* Nexus Repository for artifact storage\n",
            "* Prometheus and Grafana for deployment monitoring\n",
            "Metadata: {'file_name': 'engineering_master_doc.md', 'page_no': 22, 'access_level': 'engineer', 'heading_level': 'H3'}\n",
            "---\n",
            "Content: ### 7.2 Infrastructure as Code (IaC)\n",
            "#### 7.2.1 Cloud Infrastructure\n",
            "* **Terraform Modules**:\n",
            "* Network infrastructure (VPC, subnets, security groups)\n",
            "* Compute resources (EC2, ECS, Lambda)\n",
            "* Database services (RDS, DynamoDB)\n",
            "* Storage and CDN (S3, CloudFront)\n",
            "* **Version Control**:\n",
            "* Infrastructure code in Git repository\n",
            "* PR-based changes with peer review\n",
            "* Change approval process for production infrastructure\n",
            "#### 7.2.2 Application Configuration\n",
            "* **Kubernetes Resources**:\n",
            "* Helm charts for all microservices\n",
            "* Kustomize for environment-specific configurations\n",
            "* ConfigMaps and Secrets for application settings\n",
            "* **Config Management**:\n",
            "* Environment variables for non-sensitive configuration\n",
            "* AWS Parameter Store for sensitive configuration\n",
            "* Feature flags via LaunchDarkly\n",
            "#### 7.2.3 IaC Security\n",
            "* Terraform scanning with Checkov\n",
            "* IAM permissions audit with CloudTracker\n",
            "* Kubernetes security scanning with Kubesec\n",
            "Metadata: {'file_name': 'engineering_master_doc.md', 'page_no': 23, 'access_level': 'engineer', 'heading_level': 'H3'}\n",
            "---\n",
            "Content: ### 7.3 Containerization Strategy\n",
            "#### 7.3.1 Docker Standards\n",
            "* Minimal base images (Alpine where possible)\n",
            "* Multi-stage builds to minimize image size\n",
            "* Non-root user execution\n",
            "* Image scanning with Trivy\n",
            "#### 7.3.2 Kubernetes Configuration\n",
            "* Resource limits and requests for all containers\n",
            "* Pod security policies enforced\n",
            "* Network policies controlling pod-to-pod communication\n",
            "* Horizontal Pod Autoscalers based on custom metrics\n",
            "#### 7.3.3 Registry and Artifact Management\n",
            "* Private Docker registry with vulnerability scanning\n",
            "* Image promotion process across environments\n",
            "* Immutable tags with git commit hashes\n",
            "* Image retention policies\n",
            "Metadata: {'file_name': 'engineering_master_doc.md', 'page_no': 24, 'access_level': 'engineer', 'heading_level': 'H3'}\n",
            "---\n",
            "Content: ### 7.4 Release Management\n",
            "#### 7.4.1 Release Planning\n",
            "* Bi-weekly release schedule\n",
            "* Release planning meeting at sprint start\n",
            "* Release readiness review before deployment\n",
            "#### 7.4.2 Release Process\n",
            "* Release branch created from `develop`\n",
            "* Regression testing on release branch\n",
            "* Release notes compiled from Jira tickets\n",
            "* Change Advisory Board approval for production deployment\n",
            "#### 7.4.3 Hotfix Process\n",
            "* Critical issues patched directly from `main`\n",
            "* Abbreviated testing focused on the specific issue\n",
            "* Immediate deployment with post-deployment verification\n",
            "* Patch merged back to `develop` branch\n",
            "Metadata: {'file_name': 'engineering_master_doc.md', 'page_no': 25, 'access_level': 'engineer', 'heading_level': 'H3'}\n"
          ]
        }
      ],
      "source": [
        "# Example output\n",
        "for doc in docs_engineering[20:25]:\n",
        "    print(\"---\")\n",
        "    print(\"Content:\", doc.page_content)\n",
        "    print(\"Metadata:\", doc.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "ff409ea6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff409ea6",
        "outputId": "daab41ff-8c50-443a-b6ed-a83810b88542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After adding Engineering report 140\n"
          ]
        }
      ],
      "source": [
        "# Append to the processed file\n",
        "for doc_id in range(len(docs_engineering)):\n",
        "    processed_docs.append(docs_engineering[doc_id])\n",
        "print('After adding Engineering report', len(processed_docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13ae860b",
      "metadata": {
        "id": "13ae860b"
      },
      "source": [
        "#### General"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "de66377a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de66377a",
        "outputId": "32f6b1e0-dd2b-4bab-c9f8-10163f4eb269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens in 'data/general/employee_handbook.md': 3019\n"
          ]
        }
      ],
      "source": [
        "count_tokens_in_file('data/general/employee_handbook.md')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "2c90817c",
      "metadata": {
        "id": "2c90817c"
      },
      "outputs": [],
      "source": [
        "docs_general = parse_markdown_with_headings(file_path = \"data/general/employee_handbook.md\",access_level=\"employee\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "7627a622",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7627a622",
        "outputId": "8c1ebf8d-971d-4321-b9e4-58f24d27705c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content: ## Table of Contents\n",
            "1. [Welcome & Introduction](#welcome--introduction)\n",
            "2. [Employee Onboarding & Benefits](#employee-onboarding--benefits)\n",
            "3. [Leave Policies](#leave-policies)\n",
            "4. [Work Hours & Attendance](#work-hours--attendance)\n",
            "5. [Code of Conduct & Workplace Behavior](#code-of-conduct--workplace-behavior)\n",
            "6. [Health & Safety](#health--safety)\n",
            "7. [Compensation & Payroll](#compensation--payroll)\n",
            "8. [Reimbursement Policies](#reimbursement-policies)\n",
            "9. [Training & Development](#training--development)\n",
            "10. [Performance & Feedback](#performance--feedback)\n",
            "11. [Privacy & Data Security](#privacy--data-security)\n",
            "12. [Exit Policy](#exit-policy)\n",
            "13. [FAQs](#faqs)\n",
            "14. [Miscellaneous](#miscellaneous)\n",
            "---\n",
            "Metadata: {'file_name': 'employee_handbook.md', 'page_no': 1, 'access_level': 'employee', 'heading_level': 'H2'}\n",
            "************************\n",
            "Content: ### Company Vision and Mission\n",
            "At FinSolve Technologies, our vision is to empower businesses and individuals through innovative technology solutions. Our mission is to deliver high-quality, sustainable products and services that create value for our stakeholders.\n",
            "Metadata: {'file_name': 'employee_handbook.md', 'page_no': 2, 'access_level': 'employee', 'heading_level': 'H3'}\n",
            "************************\n",
            "Content: ### Core Values\n",
            "- **Integrity**: We act with honesty and transparency.\n",
            "- **Respect**: We value diversity and treat everyone with dignity.\n",
            "- **Innovation**: We encourage creativity and continuous improvement.\n",
            "- **Customer Focus**: Our customers are at the heart of everything we do.\n",
            "- **Accountability**: We take responsibility for our actions and results.\n",
            "Metadata: {'file_name': 'employee_handbook.md', 'page_no': 3, 'access_level': 'employee', 'heading_level': 'H3'}\n",
            "************************\n",
            "Content: ### Company Overview\n",
            "Founded in 2016, FinSolve Technologies is a leading player in fintech with a presence across India and global markets. We are committed to ethical business, social responsibility, and fostering a culture of learning and growth.\n",
            "---\n",
            "Metadata: {'file_name': 'employee_handbook.md', 'page_no': 4, 'access_level': 'employee', 'heading_level': 'H3'}\n",
            "************************\n",
            "Content: ### Onboarding Process\n",
            "- **Pre-Joining**: Offer letter issuance, document submission (ID, address, education, previous employment).\n",
            "- **Day 1**: Welcome session, HR induction, IT setup, introduction to team and mentor.\n",
            "- **First Week**: Policy orientation, compliance training, role-specific training, buddy program.\n",
            "- **First Month**: Probation objectives set, regular check-ins with manager and HR.\n",
            "Metadata: {'file_name': 'employee_handbook.md', 'page_no': 5, 'access_level': 'employee', 'heading_level': 'H3'}\n",
            "************************\n"
          ]
        }
      ],
      "source": [
        "# Example output\n",
        "for doc in docs_general[:5]:\n",
        "    print(\"Content:\", doc.page_content)\n",
        "    print(\"Metadata:\", doc.metadata)\n",
        "    print(\"***\"*8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "64171fdf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64171fdf",
        "outputId": "060d19d6-9f86-4b2d-836c-f366678ab289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After adding docs_general report 195\n"
          ]
        }
      ],
      "source": [
        "# Append to processed_docs\n",
        "for doc_id in range(len(docs_general)):\n",
        "    processed_docs.append(docs_general[doc_id])\n",
        "print('After adding docs_general report', len(processed_docs))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73fa52e5",
      "metadata": {
        "id": "73fa52e5"
      },
      "source": [
        "#### Index Document Chunks and Embeddings in Vector DB\n",
        "\n",
        "1. Generate embeddings for each chunk using a model (e.g., OpenAI).\n",
        "\n",
        "2. Store chunks + embeddings in Chroma for efficient vector similarity search during retrieval."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b0f3462",
      "metadata": {
        "id": "0b0f3462"
      },
      "source": [
        "!pip install langchain-chroma==0.1.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "0366641f",
      "metadata": {
        "id": "0366641f"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create vector DB of docs and embeddings\n",
        "collection_info = \"rbac_rag_store\"\n",
        "chroma_db = Chroma.from_documents(documents=processed_docs,\n",
        "                                  collection_name=collection_info,\n",
        "                                  embedding=openai_embed_model,\n",
        "                                  # need to set the distance function to cosine else it uses euclidean by default\n",
        "                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n",
        "                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n",
        "                                  persist_directory=\"my_db5\")"
      ],
      "metadata": {
        "id": "bKWf-0i5utAn"
      },
      "id": "bKWf-0i5utAn",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5f799ede",
      "metadata": {
        "id": "5f799ede"
      },
      "source": [
        "### Load Vector DB from disk\n",
        "\n",
        "Once a vector database has been created and persisted to disk, you can easily reload it at any time without regenerating embeddings.\n",
        "\n",
        "- **Cost-Effective**: Generating embeddings (especially using OpenAI or proprietary models) incurs costs. By saving the vector store after initial creation, you avoid repeating that expense\n",
        "- **Faster Startup**: Loading an existing vector DB from disk is significantly faster than reprocessing and re-embedding large document sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "5b6b4e97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b6b4e97",
        "outputId": "1dd2d94f-e018-4aa1-f810-1f26a41ff955"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents in collection: 195\n"
          ]
        }
      ],
      "source": [
        "# load from disk\n",
        "collection_info = \"rbac_rag_store\"\n",
        "chroma_db = Chroma(persist_directory=\"my_db5\",\n",
        "                   collection_name = collection_info,\n",
        "                   embedding_function=openai_embed_model)\n",
        "\n",
        "print(f\"Number of documents in collection: {chroma_db._collection.count()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9a24a26",
      "metadata": {
        "id": "d9a24a26"
      },
      "source": [
        "### Semantic Similarity based Retrieval\n",
        "\n",
        "We use simple cosine similarity here and retrieve the top 3 similar documents based on the user input query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "67e64b0a",
      "metadata": {
        "id": "67e64b0a"
      },
      "outputs": [],
      "source": [
        "similarity_retriever = chroma_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
        "                                              search_kwargs={\"k\": 3, \"score_threshold\": 0.1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "fe49cdd9",
      "metadata": {
        "id": "fe49cdd9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "def display_docs(docs):\n",
        "    for doc in docs:\n",
        "        print('Metadata:', doc.metadata)\n",
        "        print('Content Brief:')\n",
        "        display(Markdown(doc.page_content))\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "9a75af6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "9a75af6b",
        "outputId": "64b38e5a-565a-434f-89b7-583e070d384a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata: {'access_level': 'employee', 'file_name': 'employee_handbook.md', 'heading_level': 'H3', 'page_no': 11}\n",
            "Content Brief:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Attendance & Punctuality\n- Attendance must be marked daily via biometric, swipe card, or HRMS app.\n- Late arrivals/early departures must be notified to the manager.\n- Three or more late arrivals in a month may attract disciplinary action."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata: {'access_level': 'employee', 'file_name': 'employee_handbook.md', 'heading_level': 'H2', 'page_no': 51}\n",
            "Content Brief:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## FAQs\n**Q: How do I apply for maternity leave?**\nA: Submit application on HRMS with medical certificate at least 8 weeks before due date.\n**Q: What if I forget to mark attendance?**\nA: Inform HR within 24 hours; repeated lapses may lead to deduction or disciplinary action.\n**Q: How is overtime calculated?**\nA: Paid at double the regular wage for hours beyond statutory limits, subject to manager approval.\n**Q: Can I work from home?**\nA: Up to 2 days/week, subject to manager and business approval.\n---"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata: {'access_level': 'employee', 'file_name': 'employee_handbook.md', 'heading_level': 'H3', 'page_no': 55}\n",
            "Content Brief:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Dress Code & Office Etiquette\n- Maintain cleanliness of workspace.\n- Use meeting rooms for calls/discussions.\n- Mobile phones on silent in work areas.\n---\n**Note**: This handbook is a living document and may be updated periodically. For policy clarifications or state-specific rules, please consult HR or refer to the company’s policy portal."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the companys policy on attendance and late arrivals?\"\n",
        "top_docs = similarity_retriever.invoke(query)\n",
        "display_docs(top_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53ae7f21",
      "metadata": {
        "id": "53ae7f21"
      },
      "source": [
        "## Build the RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "9ed56936",
      "metadata": {
        "id": "9ed56936"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "rag_prompt = \"\"\"You are an assistant who is an expert in question-answering tasks.\n",
        "                Answer the following question using only the following pieces of retrieved context.\n",
        "                If the answer is not in the context, do not make up answers, just say that you don't know.\n",
        "                Keep the answer to the point based on the information from the context.\n",
        "\n",
        "                Question:\n",
        "                {question}\n",
        "\n",
        "                Context:\n",
        "                {context}\n",
        "\n",
        "                Answer:\n",
        "            \"\"\"\n",
        "\n",
        "# convert the raw template in to structured one,\n",
        "# so we can easily ingest <question> and <context>\n",
        "rag_prompt_template = ChatPromptTemplate.from_template(rag_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "c6379069",
      "metadata": {
        "id": "c6379069"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from operator import itemgetter\n",
        "\n",
        "\n",
        "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "src_rag_response_chain = (\n",
        "    {\n",
        "        \"context\": (itemgetter('context')\n",
        "                        |\n",
        "                    RunnableLambda(format_docs)),\n",
        "        \"question\": itemgetter(\"question\")\n",
        "    }\n",
        "        |\n",
        "    rag_prompt_template\n",
        "        |\n",
        "    chatgpt\n",
        "        |\n",
        "    StrOutputParser()\n",
        ")\n",
        "\n",
        "rag_chain_w_sources = (\n",
        "    {\n",
        "        \"context\": similarity_retriever,\n",
        "        \"question\": RunnablePassthrough()\n",
        "    }\n",
        "        |\n",
        "    RunnablePassthrough.assign(response=src_rag_response_chain)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "63fe5b2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63fe5b2b",
        "outputId": "bbfff6a3-38ca-4d9e-eab1-9e72544b4dd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': [Document(metadata={'access_level': 'employee', 'file_name': 'employee_handbook.md', 'heading_level': 'H3', 'page_no': 8}, page_content='### Leave Application Process\\n- Apply via HRMS/leave portal at least 3 days in advance (except emergencies).\\n- Sick leave for more than 2 days requires a medical certificate.\\n- Emergency leave to be communicated to manager/HR as soon as possible.\\n- Approval from reporting manager and HR required for all leave requests.\\n- Leave balance can be viewed on the HRMS portal.'),\n",
              "  Document(metadata={'access_level': 'employee', 'file_name': 'employee_handbook.md', 'heading_level': 'H3', 'page_no': 7}, page_content='### Types of Leave\\n| Leave Type | Entitlement/Details |\\n|------------|---------------------|\\n| **Privilege/Annual** | 15-21 days/year (as per state Shops & Establishments Act); accrued monthly |\\n| **Sick Leave** | 12 days/year (non-cumulative; medical certificate for >2 days) |\\n| **Casual Leave** | 7 days/year (state-specific) |\\n| **Maternity Leave** | 26 weeks (first two children); 12 weeks for subsequent children |\\n| **Paternity Leave** | 7-15 days (company policy; not statutory) |\\n| **Bereavement Leave** | 3-7 days for immediate family (company policy) |\\n| **Compensatory Off** | For work on holidays/weekends (manager approval required) |\\n| **Public Holidays** | 10-14 days/year (as per company calendar and state notifications) |\\n| **Leave Without Pay** | Allowed with approval after exhausting paid leave |'),\n",
              "  Document(metadata={'access_level': 'employee', 'file_name': 'employee_handbook.md', 'heading_level': 'H2', 'page_no': 51}, page_content='## FAQs\\n**Q: How do I apply for maternity leave?**\\nA: Submit application on HRMS with medical certificate at least 8 weeks before due date.\\n**Q: What if I forget to mark attendance?**\\nA: Inform HR within 24 hours; repeated lapses may lead to deduction or disciplinary action.\\n**Q: How is overtime calculated?**\\nA: Paid at double the regular wage for hours beyond statutory limits, subject to manager approval.\\n**Q: Can I work from home?**\\nA: Up to 2 days/week, subject to manager and business approval.\\n---')],\n",
              " 'question': 'who will approve my leave request?',\n",
              " 'response': 'Your leave request will be approved by your reporting manager and HR.'}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "query = \"who will approve my leave request?\"\n",
        "result = rag_chain_w_sources.invoke(query)\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a08947cd",
      "metadata": {
        "id": "a08947cd"
      },
      "source": [
        "## Build the RAG Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "b6ab5108",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "b6ab5108",
        "outputId": "6daa95c3-01b8-4093-dabc-8dd9b53aaddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of documents in collection: 195\n",
            "Question: What is the purpose of the engineering document?\\n\n",
            "Role: engineer\\n\n",
            "Answer: The purpose of the engineering document is to outline the technical architecture, development processes, and operational guidelines for FinSolve's product ecosystem, serving as a comprehensive guide for engineering teams, stakeholders, and partners to ensure alignment with FinSolve's mission.\\n\n",
            "--- Retrieved Context ---\n",
            "Metadata: {'access_level': 'engineer', 'file_name': 'engineering_master_doc.md', 'heading_level': 'H3', 'page_no': 2}\n",
            "Content Brief:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### 1.2 Purpose\nThis engineering document outlines the technical architecture, development processes, and operational guidelines for FinSolve's product ecosystem. It serves as a comprehensive guide for engineering teams, stakeholders, and partners to ensure alignment with FinSolve's mission: \"To empower financial freedom through secure, scalable, and innovative technology solutions.\""
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata: {'access_level': 'engineer', 'file_name': 'engineering_master_doc.md', 'heading_level': 'H3', 'page_no': 4}\n",
            "Content Brief:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### 1.4 Document Control\n| Version | Date | Author | Changes |\n|---------|------|--------|---------|\n| 1.0 | 2025-05-01 | Engineering Team | Initial version |\n| 1.1 | 2025-05-14 | Tech Architecture Council | Updated diagrams and monitoring section |"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Metadata: {'access_level': 'engineer', 'file_name': 'engineering_master_doc.md', 'heading_level': 'H3', 'page_no': 32}\n",
            "Content Brief:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### 10.2 Reference Documents\n| Document | Location | Purpose |\n|----------|----------|---------|\n| AWS Well-Architected Framework | Internal Wiki | Cloud architecture best practices |\n| PCI-DSS Guidelines | Security Portal | Payment security compliance |\n| Kubernetes Documentation | kubernetes.io | Container orchestration reference |\n| OWASP Security Standards | Internal Wiki | Web application security |\n| Data Protection Policy | Legal Repository | Data handling requirements |"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "from operator import itemgetter\n",
        "\n",
        "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# load from disk\n",
        "collection_info = \"rbac_rag_store\"\n",
        "chroma_db = Chroma(persist_directory=\"my_db5\",\n",
        "                   collection_name = collection_info,\n",
        "                   embedding_function=openai_embed_model)\n",
        "\n",
        "print(f\"Number of documents in collection: {chroma_db._collection.count()}\")\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "def get_rbac_retriever(user_role: str):\n",
        "    \"\"\"\n",
        "    Creates a retriever that filters documents based on the user's role.\n",
        "    \"\"\"\n",
        "    return chroma_db.as_retriever(\n",
        "        search_type=\"similarity\",\n",
        "        search_kwargs={\"k\": 3, \"filter\": {\"access_level\": user_role}}\n",
        "    )\n",
        "\n",
        "src_rag_response_chain = (\n",
        "    {\n",
        "        \"context\": (itemgetter('context')\n",
        "                        |\n",
        "                    RunnableLambda(format_docs)),\n",
        "        \"question\": itemgetter(\"question\")\n",
        "    }\n",
        "        |\n",
        "    rag_prompt_template\n",
        "        |\n",
        "    chatgpt\n",
        "        |\n",
        "    StrOutputParser()\n",
        ")\n",
        "\n",
        "# This chain now expects a dictionary with \"question\" and \"user_role\"\n",
        "rag_chain_with_rbac = (\n",
        "    {\n",
        "        \"context\": lambda x: get_rbac_retriever(x[\"user_role\"]).invoke(x[\"question\"]),\n",
        "        \"question\": itemgetter(\"question\"),\n",
        "        \"user_role\": itemgetter(\"user_role\") # Pass the role along for clarity if needed\n",
        "    }\n",
        "    |\n",
        "    RunnablePassthrough.assign(response=src_rag_response_chain)\n",
        ")\n",
        "\n",
        "# Example invocation for an engineer\n",
        "hr_query = \"What is the purpose of the engineering document?\"\n",
        "result = rag_chain_with_rbac.invoke({\"question\": hr_query, \"user_role\": \"engineer\"})\n",
        "\n",
        "print(f\"Question: {result['question']}\\\\n\")\n",
        "print(f\"Role: {result['user_role']}\\\\n\")\n",
        "print(f\"Answer: {result['response']}\\\\n\")\n",
        "print(\"--- Retrieved Context ---\")\n",
        "display_docs(result['context'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5HuBJkIYvmv-"
      },
      "id": "5HuBJkIYvmv-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "my_rag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}